# ğŸš€ Proyecto ETL en Azure con Arquitectura MedallÃ³n (Bronze â†’ Silver â†’ Golden)

Este proyecto implementa un flujo completo de ingestiÃ³n, transformaciÃ³n y consumo de datos utilizando servicios de Azure. La soluciÃ³n sigue la arquitectura **MedallÃ³n** (Bronze â†’ Silver â†’ Golden) y permite mover datos desde un entorno On-Premise hasta un dashboard final en Power BI.

---

## ğŸ§© Arquitectura General

La arquitectura utilizada es la siguiente:

![Arquitectura del proyecto](/architecture/architecture.png)  


---

## ğŸ“¥ 1. Ingesta de Datos â€” On-Premise â†’ ADLS Bronze

### ğŸ”¹ Fuente de datos
- Base de datos **AdventureWorks 2019**
- SQL Server instalado de manera **On-Premise** (local)

### ğŸ”¹ Proceso de ingesta
Usando **Azure Data Factory (ADF)** se configurÃ³ una *pipeline* para:

1. Conectarse al SQL Server On-Premise
2. Extraer todas las tablas de la BD
3. Guardarlas en **Azure Data Lake Storage Gen2 (ADLS)**  
4. Formato de almacenamiento: **Parquet**
5. Capa de destino: **Bronze**

---

## ğŸ§¼ 2. TransformaciÃ³n â€” Bronze â†’ Silver (Databricks)

En **Azure Databricks** se desarrollÃ³ un notebook dedicado al procesamiento inicial de los datos.

### ğŸ“˜ Notebook 1: Limpieza y estandarizaciÃ³n (Bronze â†’ Silver)

Acciones realizadas:
- Lectura de cada tabla Parquet desde Bronze
- Limpieza de nulos y tipificaciÃ³n correcta
- NormalizaciÃ³n bÃ¡sica
- Escritura tabla por tabla en:
  - **ADLS Silver**
  - Formato **Delta Lake**

Este notebook se integrÃ³ como un **paso dentro de la pipeline de ADF**.

---

## ğŸ”„ 3. TransformaciÃ³n â€” Silver â†’ Golden (Databricks)

### ğŸ“™ Notebook 2: CuraciÃ³n final y mejoras semÃ¡nticas (Silver â†’ Golden)

Acciones realizadas:
- Lectura de tablas Delta desde Silver
- TransformaciÃ³n de nombres de columnas:
  - De formato **PascalCase**
  - A formato **snake_case** con guion bajo (`example_column`)
- Validaciones finales
- Escritura en:
  - **ADLS Golden**
  - Formato **Delta Lake**

Este notebook tambiÃ©n se agregÃ³ como un **paso dentro de la pipeline de ADF**.

---

## ğŸ“Š 4. Modelado y ExposiciÃ³n de Datos â€” Synapse Analytics

Desde **Azure Synapse Analytics**:

### ğŸ”¹ Lectura desde ADLS Golden
- Se configurÃ³ una External Data Source hacia ADLS Golden.
- Se generaron vistas externas tipo *serverless* para cada tabla Delta.

### ğŸ”¹ AutomatizaciÃ³n con Stored Procedure
Mediante un **Stored Procedure**, se generÃ³ dinÃ¡micamente una vista por cada tabla Delta encontrada en Golden.

Este Stored Procedure fue ejecutado a travÃ©s de un paso adicional en la pipeline.

---

## ğŸ“ˆ 5. Consumo â€” Power BI

Finalmente, **Power BI** se conecta a las vistas generadas en Synapse para construir visualizaciones y dashboards interactivos.

---

## ğŸ” 6. Seguridad y Gobernanza

El proyecto implementa prÃ¡cticas de seguridad y administraciÃ³n:

### âœ” Azure Active Directory
- Controla identidades y permisos del workspace
- Manejo de roles y acceso por servicio

### âœ” Azure Key Vault
- Almacena:
  - Keys
  - Secrets
  - Tokens
- Consumido por:
  - ADF
  - Synapse
  - Databricks

### âœ” External Locations en Databricks
- AdministraciÃ³n segura de permisos de lectura y escritura hacia ADLS
- Minimiza la exposiciÃ³n de credenciales

---

## ğŸ“‚ Estructura sugerida del repositorio

```txt
 ğŸ“¦ proyecto-etl-azure
â”œâ”€â”€ architecture/
â”‚ â””â”€â”€ arquitectura-medallon.png
â”œâ”€â”€ synapse/
â”‚ â”œâ”€â”€ pipelines/
â”‚ â”œâ”€â”€ sql/
â”‚ â””â”€â”€ notebooks/
â”œâ”€â”€ databricks/
â”‚ â”œâ”€â”€ bronze_to_silver.ipynb
â”‚ â””â”€â”€ silver_to_gold.ipynb
â”œâ”€â”€ adf/
â”‚ â””â”€â”€ pipelines/
â”œâ”€â”€ powerbi/
â”‚ â””â”€â”€ dashboard.pbix
â””â”€â”€ README.md
 ```


---

## ğŸ§  ConclusiÃ³n

Este proyecto muestra un flujo ETL profesional usando Azure, desde extracciÃ³n On-Premise hasta la capa de visualizaciÃ³n, incorporando buenas prÃ¡cticas de:

- Arquitectura de datos (MedallÃ³n)
- TransformaciÃ³n con Spark
- OrquestaciÃ³n con ADF
- Modelado con Synapse
- Gobernanza con Key Vault y AAD

